{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data Loaded: \n",
      "  48,000 train\n",
      "  12,000 valid\n",
      "  10,000 test\n"
     ]
    }
   ],
   "source": [
    "## Load MNIST\n",
    "## Loads MNIST Dataset from torchvision and creates train, valid, test dataloaders.\n",
    "## PyTorch\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "SPLIT = 0.8\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = datasets.MNIST(\"data\", train=False, download=True, transform=ToTensor())\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [int(SPLIT*len(train_dataset)), len(train_dataset)-int(SPLIT*len(train_dataset))], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False) # Note that shuffle is turned off for the test set\n",
    "\n",
    "print(f\"> Data Loaded: \\n  {len(train_dataset):,} train\\n  {len(valid_dataset):,} valid\\n  {len(test_dataset):,} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show image batch\n",
    "## Shows a batch of images from pytorch dataloaders\n",
    "## PyTorch, Matplotlib, Numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image_batch(dataloader, n_rows=8, figsize=(10,10)):\n",
    "    images, labels = next(iter(dataloader))\n",
    "    N = len(images)\n",
    "    fig, axs = plt.subplots(n_rows, N//n_rows, figsize=(10,10), constrained_layout=True)\n",
    "    \n",
    "    for image, label, ax in zip(images, labels, axs.ravel()[:N]):\n",
    "        ax.set_title(label.item())\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(image.squeeze())\n",
    "\n",
    "show_image_batch(train_dataloader, n_rows=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "## Set Device\n",
    "## Set the PyTorch device either to GPU or CPU\n",
    "## PyTorch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Dataset\n",
    "## The boilerplate code for creating a custom PyTorch Datast.\n",
    "## PyTorch, Pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Neural Network\n",
    "## Simple PyTorch NeuralNetwork Module\n",
    "## PyTorch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            OrderedDict([\n",
    "                (\"linear1\", nn.Linear(28*28, 512)),\n",
    "                (\"relu1\", nn.ReLU()),\n",
    "                (\"linear2\", nn.Linear(512, 512)),\n",
    "                (\"relu2\", nn.ReLU()),\n",
    "                (\"linear3\", nn.Linear(512, 10)),\n",
    "            ])\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LeNet\n",
    "## Create the LeNet Architecture in PyTorch\n",
    "## PyTorch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    # First Convolution Block\n",
    "    (\"conv1\", nn.Conv2d(1, 6, 5, padding=2)),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"avgpool1\", nn.AvgPool2d(2, stride=2)),\n",
    "    \n",
    "    # Second Convolution Block\n",
    "    (\"conv2\", nn.Conv2d(6, 16, 5, padding=2)),\n",
    "    (\"relu2\", nn.ReLU()),\n",
    "    (\"avgpool2\", nn.AvgPool2d(2, stride=2)),\n",
    "    \n",
    "    # Classifier\n",
    "    (\"flatten\", nn.Flatten()),\n",
    "    (\"linear1\", nn.Linear(784, 120)),\n",
    "    (\"relu3\", nn.ReLU()),\n",
    "    (\"linear2\", nn.Linear(120, 84)),\n",
    "    (\"relu4\", nn.ReLU()),\n",
    "    (\"linear3\", nn.Linear(84, 10)),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "## Quickly create a PyTorch loss function\n",
    "## PyTorch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\Programming\\Python\\GHD PyTorch Snippets\\snippets_notebook.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m LEARNING_RATE \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLEARNING_RATE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "## Optimizer\n",
    "## Quickly create a PyTorch optimizer\n",
    "## PyTorch\n",
    "import torch\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Training loop\n",
    "## A simple training loop for PyTorch\n",
    "## PyTorch\n",
    "\n",
    "def train_model(model, dataloader, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0057309999974677"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = time.perf_counter()\n",
    "time.sleep(2)\n",
    "b = time.perf_counter()\n",
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\Programming\\Python\\GHD PyTorch Snippets\\snippets_notebook.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest Validation Loss: \u001b[39m\u001b[39m{\u001b[39;00mbest_valid_loss\u001b[39m:\u001b[39;00m\u001b[39m.6f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X13sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_model, train_loss_history, valid_loss_history\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Programming/Python/GHD%20PyTorch%20Snippets/snippets_notebook.ipynb#X13sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m best_model, best_loss \u001b[39m=\u001b[39m train_model(model, train_dataloader, loss_fn, optimizer, epochs\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, weights_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "## Complete Training loop\n",
    "## A complete training loop with progressbar and loss history.\n",
    "## PyTorch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, current_epoch, num_epochs):\n",
    "    \n",
    "    # tqdm progressbar\n",
    "    pbar = tqdm(total=len(dataloader.dataset), desc=f\"Epoch {current_epoch}/{num_epochs} \")\n",
    "    \n",
    "    # For every batch\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        train_loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate losses\n",
    "        train_loss = train_loss.item()\n",
    "        valid_loss = train_loss # TODO: calculate validation loss\n",
    "        \n",
    "        # Update tqdm progressbar\n",
    "        pbar.set_postfix({\"Train Loss\":f\"{train_loss:.6f}\", \"Valid Loss\":f\"{valid_loss:.6f}\"})\n",
    "        pbar.update(len(X))\n",
    "        \n",
    "    return train_loss, valid_loss\n",
    "\n",
    "def train_model(model, train_dataloader, loss_fn, optimizer, epochs, weights_path=\"model.pt\"):\n",
    "    # Track time\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Best model and loss\n",
    "    best_valid_loss = float('inf')\n",
    "    best_model = model\n",
    "    \n",
    "    # Loss histories for plotting\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "    \n",
    "    # For every epoch\n",
    "    for i in range(epochs):\n",
    "        # Train step\n",
    "        train_loss, valid_loss = train_step(model, train_dataloader, loss_fn, optimizer, current_epoch=i+1, num_epochs=epochs)\n",
    "        \n",
    "        # Track losses\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model.state_dict(), weights_path)\n",
    "            tqdm.write(f\"> Best Model Saved: {weights_path}\")\n",
    "    \n",
    "    print(f\"Training Done in {time.perf_counter() - start_time} seconds.\")\n",
    "    print(f\"best Validation Loss: {best_valid_loss:.6f}\")\n",
    "    \n",
    "    return best_model, train_loss_history, valid_loss_history\n",
    "\n",
    "best_model, best_loss = train_model(model, train_dataloader, loss_fn, optimizer, epochs=4, weights_path=\"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\ghd-snippets-next\\notebook\\snippets_notebook.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/ghd-snippets-next/notebook/snippets_notebook.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     plt\u001b[39m.\u001b[39mlegend([\u001b[39m\"\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mValid Loss\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Programming/ghd-snippets-next/notebook/snippets_notebook.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Programming/ghd-snippets-next/notebook/snippets_notebook.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plot_loss(train_loss_history, valid_loss_history)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss_history' is not defined"
     ]
    }
   ],
   "source": [
    "## Plot loss\n",
    "## Plot the training and validation loss history returned by the train_model function\n",
    "## PyTorch, Matplotlib\n",
    "\n",
    "def plot_loss(train_loss_history, valid_loss_history):\n",
    "    plt.figure()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    plt.plot(np.arange(len(train_loss_history)), train_loss_history)\n",
    "    plt.plot(np.arange(len(valid_loss_history)), valid_loss_history)\n",
    "    \n",
    "    plt.legend([\"Train Loss\",\"Valid Loss\"])\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(train_loss_history, valid_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "model = Neural_Network()\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load('/content/best-weights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Torchvision transforms\n",
    "## A set of torchvision transforms ready to be passed to a Dataset\n",
    "## PyTorch\n",
    "\n",
    "from torchvision import transforms as T \n",
    "\n",
    "train_augs = T.Compose([\n",
    "    T.RandomHorizontalFlip(p = 0.5),\n",
    "    T.RandomRotation(degrees=(-20, +20)),\n",
    "    T.ToTensor()\n",
    "\n",
    "])\n",
    "\n",
    "valid_augs = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load datasets using ImageFolder\n",
    "## Load train and valid image dataset when you have folders of images for each class\n",
    "## PyTorch\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "trainset = ImageFolder(\"data/train\", transform=train_augs)\n",
    "validset = ImageFolder(\"data/valid\", transform=valid_augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PyTorch Multi Transform\n",
    "## transforms for train and valid Datasets, provided as a dictionary\n",
    "## PyTorch\n",
    "data_transforms = {\n",
    "    'train': T.Compose([\n",
    "        T.RandomResizedCrop(INPUT_SIZE),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': T.Compose([\n",
    "        T.Resize(INPUT_SIZE),\n",
    "        T.CenterCrop(INPUT_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download data if not exists\n",
    "## Downloads the data using wget only if that data hasn't been downloaded yet\n",
    "## Other\n",
    "!wget -nc https://path.com/to/file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unzip data if not exists\n",
    "## Unzips the data using unzip tool only if that data hasn't been extracted yet\n",
    "## Other\n",
    "!unzip -n \"/content/A.zip\" -d \"/content/A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unrar data if not exists\n",
    "## Unrars the data using unrar tool only if that data hasn't been extracted yet\n",
    "## Other\n",
    "!unrar -o -x \"/content/A.rar\" \"/content/A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show GPU info\n",
    "## Prints info about your gpu. useful in google colab\n",
    "## Other\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show RAM info\n",
    "## Prints info about your RAM.\n",
    "## Other\n",
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Profiling (%prun)\n",
    "## Sample code and usage of profiler in jupyter notebooks\n",
    "## Other\n",
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total\n",
    "\n",
    "%prun sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Line Profiler (%lprun)\n",
    "## Installing and usage example of line_profiler\n",
    "## Other\n",
    "!pip install line_profiler\n",
    "\n",
    "%load_ext line_profiler\n",
    "\n",
    "%lprun -f sum_of_lists sum_of_lists(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory Profiler (%memit)\n",
    "## Installing and usage example of memory_profiler\n",
    "## Other\n",
    "!pip install memory_profiler\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%memit sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Loading and Preperation\n",
    "## Loads a dataset, shuffles it, splits it into train and test set and seperates label from features\n",
    "## Pandas\n",
    "# Load data\n",
    "df = pd.read_csv(\"/content/heart.csv\")\n",
    "\n",
    "# Shuffle dataframe\n",
    "df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "# Seperate X,y\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Split to train and test\n",
    "split = 0.7\n",
    "\n",
    "X_train = X.iloc[ : int(len(X)*split),:].reset_index(drop=True)\n",
    "X_test = X.iloc[int(len(X)*split) : ,:].reset_index(drop=True)\n",
    "\n",
    "y_train = y.iloc[ : int(len(X)*split)].reset_index(drop=True)\n",
    "y_test = y.iloc[int(len(X)*split) : ].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train X size = {len(X_train)}\")\n",
    "print(f\"Train y size = {len(y_train)}\")\n",
    "print(f\"Test X size = {len(X_test)}\")\n",
    "print(f\"Test y size = {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas Complete read_csv\n",
    "## read_csv but with custom sperator and header names\n",
    "## Pandas\n",
    "# Custom 'sep', 'Nan symbol' and 'header_names'\n",
    "df = pd.read_csv('crx.data', header=None, sep=\",\", na_values=[\"?\"], names=[\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Columns with Missing Values\n",
    "## What columns of a pandas DataFrame have missing values and how many?\n",
    "## Pandas\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot encode Categorical Data\n",
    "## One-hot encode categorical data pandas DataFrame\n",
    "## Pandas\n",
    "for col in train_df.dtypes[train_df.dtypes == 'object'].index:\n",
    "    for_dummy = train_df.pop(col)\n",
    "    train_df = pd.concat([train_df, pd.get_dummies(for_dummy, prefix=col)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matplotlib customizations\n",
    "## \n",
    "## Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"dark\") # to disable gridlines\n",
    "\n",
    "# Subplots\n",
    "fig, axs = plt.subplots(5, 4, figsize=(20,10), dpi=100)\n",
    "\n",
    "# Disable Ticks\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matplotlib disable ticks\n",
    "## Matplotlib disable ticks\n",
    "## Matplotlib\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matplotlib text\n",
    "## Matplotlib text customizations\n",
    "## Matplotlib\n",
    "ax.text(0.5,\n",
    "        -0.09,\n",
    "        \"Hiiii\",\n",
    "        transform=ax.transAxes,\n",
    "        c=\"r\",\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center',\n",
    "        fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot confusion matrix\n",
    "## Plot confusion matrix using sk-learn's 'ConfusionMatrixDisplay'\n",
    "## Matplotlib, sk-learn\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=PASS_HERE, display_labels=labels)\n",
    "disp.plot(cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot histogram of pandas columns\n",
    "## Plot histogram of pandas columns\n",
    "## Pandas\n",
    "# Continuous Feature\n",
    "sns.histplot(data=df.column_name, bins=30, kde=True, color='green')\n",
    "\n",
    "# Categorical Feature\n",
    "sns.histplot(data=df.column_name)\n",
    "df.column_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensorboard, Early Stopping and Epoch Dots\n",
    "## \n",
    "## Tensorflow\n",
    "!pip install git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "# pass this callback to the 'fit' function\n",
    "def get_callbacks(name):\n",
    "  return [\n",
    "\t\t# useful for trainings with a lot of epochs prints \".\" instead of every epoch\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "\t\t# performs early stopping \n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_binary_crossentropy', patience=200),\n",
    "\t\t# saves data for tensorboard\n",
    "    tf.keras.callbacks.TensorBoard(logdir/name),\n",
    "  ]\n",
    "\n",
    "# ANDDDD\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Open an embedded TensorBoard viewer\n",
    "%tensorboard --logdir {logdir}\n",
    "\n",
    "# ORRRRR\n",
    "# upload to tensorboard.dev \n",
    "tensorboard dev upload --logdir  {logdir}\n",
    "\n",
    "# and add an IFrame into the notebook\n",
    "display.IFrame(\n",
    "    src=\"https://tensorboard.dev/experiment/vW7jmmF9TmKmy3rbheMQpw/#scalars&_smoothingWeight=0.97\",\n",
    "    width=\"100%\", height=\"800px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fourier Analysis\n",
    "## Quickly display the magnitude and phase of an image using fourier analysis\n",
    "## OpenCV\n",
    "def fourier_analysis(img):\n",
    "    fourier_img = cv2.dft(img.astype(np.float32), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    fourier_img_shift = np.fft.fftshift(fourier_img)\n",
    "    real = fourier_img_shift[:,:,0]\n",
    "    imag = fourier_img_shift[:,:,1]\n",
    "    magnitude = cv2.magnitude(real, imag)\n",
    "    phase = cv2.phase(real, imag)\n",
    "    return magnitude, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Fourier Filter\n",
    "## Applies fourier filter to an image given the mask and returns the filtered image\n",
    "## OpenCV\n",
    "def apply_fourier_filter(img, mask):\n",
    "    mask = mask[:, :, np.newaxis]\n",
    "    img_fourier = cv2.dft(img.astype(np.float32), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    img_fourier_shift = np.fft.fftshift(img_fourier)\n",
    "    img_fourier_shift *= mask\n",
    "    img_fourier_shift_back = np.fft.ifftshift(img_fourier_shift)\n",
    "    img_fourier_inverse = cv2.idft(img_fourier_shift_back, flags=cv2.DFT_SCALE)\n",
    "\n",
    "    return img_fourier_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GHD OpenCV utilities\n",
    "## simple functions like disp, rgb, bgr, uint8ify for quickly prototyping opencv code\n",
    "## OpenCV\n",
    "def rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def bgr(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def disp(img, title='', s=8, vmin=None, vmax=None):\n",
    "    plt.figure(figsize=(s,s))\n",
    "    plt.axis('off')\n",
    "    if vmin is not None and vmax is not None:\n",
    "        plt.imshow(img, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def uint8ify(img):\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    img *= 255\n",
    "    return np.uint8(img)\n",
    "\n",
    "def overlay(a,b):\n",
    "    # a and b should be float images and between 0-1\n",
    "\n",
    "    mask = a >= 0.5 # generate boolean mask of everywhere a > 0.5 \n",
    "    ab = np.zeros_like(a) # generate an output container for the blended image \n",
    "\n",
    "    # now do the blending \n",
    "    ab[~mask] = (2*a*b)[~mask] # 2ab everywhere a<0.5\n",
    "    ab[mask] = (1-2*(1-a)*(1-b))[mask] # else this\n",
    "    \n",
    "    return ab\n",
    "\n",
    "def before_after(img_a, img_b, name='', vmin=None, vmax=None, effect_name='Processed'):\n",
    "    fig, axs = plt.subplots(1,2, constrained_layout=True, figsize=(10,4))\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[0].set_title(f'{name} Original')\n",
    "    axs[1].set_title(f'{name} {effect_name}')\n",
    "    if vmin is not None and vmax is not None:\n",
    "        axs[0].imshow(img_a, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        axs[1].imshow(img_b, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        axs[0].imshow(img_a, cmap='gray')\n",
    "        axs[1].imshow(img_b, cmap='gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
